{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invariant Risk Minimization\n",
    "\n",
    "Exploration of the paper https://arxiv.org/pdf/1907.02893v2.pdf\n",
    "\n",
    "Pytorch code: https://github.com/facebookresearch/InvariantRiskMinimization/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â 0) Dataset exploration/setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Multiply\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv3D, MaxPool3D\n",
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "# convert to RGB\n",
    "x_train = np.stack((x_train,)*3, axis=-1)\n",
    "x_test = np.stack((x_test,)*3, axis=-1)\n",
    "\n",
    "# normalize\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# binary label\n",
    "y_train = (y_train < 5).astype(int)\n",
    "y_test = (y_test < 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAOVElEQVR4nO3df4xV9ZnH8c8jBYkDGlh0JNasbCXRilEIanHNhk1DZTERMLGWyIZl1WlMDcXUn93Ejm6MP7J0Y/yjyTRiadPSNAGRNMaiSJZdNQ34YxWFdkYzBnBgQtSUqoEVnv1jzuxOdc73jvecc8+F5/1KJvfe89xzz5OrH86553vv+Zq7C8DJ75S6GwDQGoQdCIKwA0EQdiAIwg4E8ZVWbszMOPUPVMzdbbTlhfbsZrbQzP5gZn1mdk+R1wJQLWt2nN3Mxkn6o6QFkvZJ2iFpmbu/nViHPTtQsSr27JdL6nP3d939qKRfS1pc4PUAVKhI2M+RtHfE433Zsr9gZl1mttPMdhbYFoCCKj9B5+49knokDuOBOhXZs++XdO6Ix1/NlgFoQ0XCvkPSTDObYWYTJH1H0uZy2gJQtqYP4939MzO7TdLvJI2TtNbd3yqtMwClanroramN8ZkdqFwlX6oBcOIg7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IIimp2wGJGny5MnJ+qRJk3Jr11xzTXLds846K1lfs2ZNsn7kyJFkPZpCYTezfkmHJR2T9Jm7zy2jKQDlK2PP/vfufqiE1wFQIT6zA0EUDbtL2mJmr5hZ12hPMLMuM9tpZjsLbgtAAUUP469y9/1mdpak58xsj7tvH/kEd++R1CNJZuYFtwegSYX27O6+P7sdlPSUpMvLaApA+ZoOu5l1mNnk4fuSviVpV1mNAShXkcP4TklPmdnw6/zK3Z8tpSu0zIwZM5L1u+66K1mfN29esj5r1qwv3dNYnX322cn6qlWrKtv2iajpsLv7u5IuKbEXABVi6A0IgrADQRB2IAjCDgRB2IEgzL11X2rjG3TVuOCCC3Jrq1evTq67fPnyZH3ixInJejb0mmvv3r25tcOHDyfXvfDCC5P1Q4fSv7+aP39+bm3Pnj3JdU9k7j7qfxT27EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBJeSbgNnnHFGsv7II48k6zfccENurdGlnovq7e1N1q+++urc2oQJE5Lr7t69O1mfNm1aoXo07NmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjG2dvA0qVLk/Wbb765RZ180TvvvJOsL1iwIFlP/Z595syZTfWE5rBnB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgGGdvA9dff31lr93f35+s79ixI1m/++67k/XUOHojqevdo3wN9+xmttbMBs1s14hlU83sOTPrzW6nVNsmgKLGchj/M0kLP7fsHklb3X2mpK3ZYwBtrGHY3X27pA8+t3ixpHXZ/XWSlpTcF4CSNfuZvdPdB7L7ByR15j3RzLokdTW5HQAlKXyCzt09NWGju/dI6pGY2BGoU7NDbwfNbLokZbeD5bUEoArNhn2zpBXZ/RWSni6nHQBVaXgYb2brJc2XNM3M9kn6kaSHJf3GzG6S9J6kb1fZ5MnulltuSda7utKnPLZs2ZJb6+vrS647OFjfQVlnZ+6pHlSgYdjdfVlO6Zsl9wKgQnxdFgiCsANBEHYgCMIOBEHYgSD4iWsbeP/995P17u7u1jTSYvPmzau7hVDYswNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIyzB7dq1apkvaOjI1k3s2TdPf/iRBdffHFy3UZeeumlZP3ll18u9PonG/bsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAE4+wngNNOOy1Zv+iii3Jr9913X3LdRYsWNdXTsFNOSe8vjh8/3vRrDwwMJOsrV65M1o8dO9b0tk9G7NmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjG2Vtg/Pjxyfrs2bOT9Q0bNiTr06dPz619+umnyXUbjWU3+s34woULk/VG3xFIGTduXLJ+3XXXJeuPPfZYbu3o0aNN9XQia7hnN7O1ZjZoZrtGLOs2s/1m9nr2V+ybGQAqN5bD+J9JGu2f739390uzv2fKbQtA2RqG3d23S/qgBb0AqFCRE3S3mdkb2WH+lLwnmVmXme00s50FtgWgoGbD/hNJX5N0qaQBSWvynujuPe4+193nNrktACVoKuzuftDdj7n7cUk/lXR5uW0BKFtTYTezkWM9SyXtynsugPZgqet6S5KZrZc0X9I0SQcl/Sh7fKkkl9Qv6bvunh6wHXqt9MZOUBMmTEjWG41Fb9y4sdD277///tzaCy+8kFz3xRdfTNanTp2arDd6/VmzZiXrVbrxxhtza5s2bUque+TIkbLbaRl3H/Vi/g2/VOPuy0ZZ/EThjgC0FF+XBYIg7EAQhB0IgrADQRB2IIiGQ2+lbuwEHnpL/Uz1gQceSK575513Ftr2s88+m6wvX748t/bRRx8l1z3zzDOT9WeeSf/Gac6cOcl66qekjz76aHLdRsN2ixcvTtZTnn/++WS9UW8ffvhh09uWpNdee63Q+il5Q2/s2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZM40uW/zggw/m1u64447kuh9//HGyfu+99ybr69evT9ZTY76XXXZZct3HH388WZ87N32Bob6+vmT91ltvza1t27Ytue7pp5+erF955ZXJeuonrtdee21y3Y6OjmS9kb179ybrM2bMKPT6KYyzA8ERdiAIwg4EQdiBIAg7EARhB4Ig7EAQjLNnUuPBUno8+pNPPkmu29XVlaxv2bIlWb/iiiuS9ZUrV+bWFi1KT7A7ceLEZL3Rb/WffPLJZL3ReHNdli0b7aLJ/y81Rj8Wt99+e7Le29tb6PVTGGcHgiPsQBCEHQiCsANBEHYgCMIOBEHYgSAYZ88MDKRnnE5dX73R9L579uxJ1hv9dvr8889P1ovo7u5O1h966KFk/dixYyV2gzI0Pc5uZuea2TYze9vM3jKz72fLp5rZc2bWm91OKbtpAOUZy2H8Z5J+4O5fl/QNSd8zs69LukfSVnefKWlr9hhAm2oYdncfcPdXs/uHJe2WdI6kxZLWZU9bJ2lJVU0CKO4rX+bJZnaepNmSfi+p092HP+gekNSZs06XpPSXwwFUbsxn481skqQNkla7+59G1nzoLN+oJ9/cvcfd57p7+sqFACo1prCb2XgNBf2X7r4xW3zQzKZn9emSBqtpEUAZGh7Gm5lJekLSbnf/8YjSZkkrJD2c3T5dSYctcuDAgWQ9NfR26qmnJte95JJLmuppWKNpk7dv355b27RpU3Ld/v7+ZJ2htZPHWD6z/62kf5T0ppm9ni37oYZC/hszu0nSe5K+XU2LAMrQMOzu/l+SRh2kl/TNctsBUBW+LgsEQdiBIAg7EARhB4Ig7EAQ/MQ1M3ny5GR9yZL8r/7PmTMnue7gYPr7RmvXrk3WU1MyS9LRo0eTdcTCpaSB4Ag7EARhB4Ig7EAQhB0IgrADQRB2IAjG2YGTDOPsQHCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EETDsJvZuWa2zczeNrO3zOz72fJuM9tvZq9nf4uqbxdAsxpevMLMpkua7u6vmtlkSa9IWqKh+dj/7O7/NuaNcfEKoHJ5F68Yy/zsA5IGsvuHzWy3pHPKbQ9A1b7UZ3YzO0/SbEm/zxbdZmZvmNlaM5uSs06Xme00s52FOgVQyJivQWdmkyT9h6QH3X2jmXVKOiTJJf2rhg71/7nBa3AYD1Qs7zB+TGE3s/GSfivpd+7+41Hq50n6rbvPavA6hB2oWNMXnDQzk/SEpN0jg56duBu2VNKuok0CqM5YzsZfJek/Jb0p6Xi2+IeSlkm6VEOH8f2SvpudzEu9Fnt2oGKFDuPLQtiB6nHdeCA4wg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBANLzhZskOS3hvxeFq2rB21a2/t2pdEb80qs7e/ziu09PfsX9i42U53n1tbAwnt2lu79iXRW7Na1RuH8UAQhB0Iou6w99S8/ZR27a1d+5LorVkt6a3Wz+wAWqfuPTuAFiHsQBC1hN3MFprZH8ysz8zuqaOHPGbWb2ZvZtNQ1zo/XTaH3qCZ7RqxbKqZPWdmvdntqHPs1dRbW0zjnZhmvNb3ru7pz1v+md3Mxkn6o6QFkvZJ2iFpmbu/3dJGcphZv6S57l77FzDM7O8k/VnSz4en1jKzRyV94O4PZ/9QTnH3u9ukt259yWm8K+otb5rxf1KN712Z0583o449++WS+tz9XXc/KunXkhbX0Efbc/ftkj743OLFktZl99dp6H+WlsvprS24+4C7v5rdPyxpeJrxWt+7RF8tUUfYz5G0d8TjfWqv+d5d0hYze8XMuupuZhSdI6bZOiCps85mRtFwGu9W+tw0423z3jUz/XlRnKD7oqvcfY6kf5D0vexwtS350Gewdho7/Ymkr2loDsABSWvqbCabZnyDpNXu/qeRtTrfu1H6asn7VkfY90s6d8Tjr2bL2oK7789uByU9paGPHe3k4PAMutntYM39/B93P+jux9z9uKSfqsb3LptmfIOkX7r7xmxx7e/daH216n2rI+w7JM00sxlmNkHSdyRtrqGPLzCzjuzEicysQ9K31H5TUW+WtCK7v0LS0zX28hfaZRrvvGnGVfN7V/v05+7e8j9JizR0Rv4dSf9SRw85ff2NpP/O/t6quzdJ6zV0WPc/Gjq3cZOkv5K0VVKvpOclTW2j3n6hoam939BQsKbX1NtVGjpEf0PS69nforrfu0RfLXnf+LosEAQn6IAgCDsQBGEHgiDsQBCEHQiCsANBEHYgiP8F9xRyWhvJGyQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[5])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env(x, y, e, labelflip_proba=.25):\n",
    "    x = x.copy()\n",
    "    y = y.copy()\n",
    "    \n",
    "    y = np.logical_xor(\n",
    "        y,\n",
    "        (np.random.random(size=len(y)) < labelflip_proba).astype(int)\n",
    "    ).astype(int)\n",
    "    \n",
    "    color = np.logical_xor(\n",
    "        y,\n",
    "        (np.random.random(size=len(y)) < e).astype(int)\n",
    "    )\n",
    "    \n",
    "    x[color, :, :, 2] = 0\n",
    "    x[color, :, :, 1] = 0\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_env(x_train, y_train, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f36951f8f50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3695163a50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=(28, 28, 3)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss=keras.losses.binary_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy', 'crossentropy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                294944    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 314,369\n",
      "Trainable params: 314,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "get_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2) checkÂ model is good for the initial task (greyscale + no label flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.0098 - accuracy: 0.9959 - crossentropy: 0.0098 - val_loss: 9.9567e-07 - val_accuracy: 1.0000 - val_crossentropy: 9.9567e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f36945c39d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model().fit(*get_env(x_train, y_train, 0),\n",
    "                batch_size=128,\n",
    "                epochs=1,\n",
    "                verbose=1,\n",
    "                validation_data=get_env(x_test, y_test, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â 0.3) our 3 envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = get_env(x_train[:10000], y_train[:10000], .1)\n",
    "e2 = get_env(x_train[10000:20000], y_train[10000:20000], .2)\n",
    "e3 = get_env(x_train[20000:30000], y_train[20000:30000], .9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Claim:Â ERM in separate envs are fooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "10000/10000 [==============================] - 3s 256us/step - loss: 0.3809 - accuracy: 0.8827 - crossentropy: 0.3809 - val_loss: 1.9649 - val_accuracy: 0.0957 - val_crossentropy: 1.9649\n",
      "Epoch 2/5\n",
      "10000/10000 [==============================] - 2s 240us/step - loss: 0.3392 - accuracy: 0.8996 - crossentropy: 0.3392 - val_loss: 1.7764 - val_accuracy: 0.0957 - val_crossentropy: 1.7764\n",
      "Epoch 3/5\n",
      "10000/10000 [==============================] - 2s 229us/step - loss: 0.3300 - accuracy: 0.8998 - crossentropy: 0.3300 - val_loss: 1.7693 - val_accuracy: 0.0961 - val_crossentropy: 1.7693\n",
      "Epoch 4/5\n",
      "10000/10000 [==============================] - 2s 231us/step - loss: 0.3191 - accuracy: 0.8999 - crossentropy: 0.3191 - val_loss: 1.6670 - val_accuracy: 0.1075 - val_crossentropy: 1.6670\n",
      "Epoch 5/5\n",
      "10000/10000 [==============================] - 2s 232us/step - loss: 0.3176 - accuracy: 0.8998 - crossentropy: 0.3176 - val_loss: 1.5179 - val_accuracy: 0.0957 - val_crossentropy: 1.5179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f36446d0850>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model().fit(*e1,\n",
    "                batch_size=128,\n",
    "                epochs=5,\n",
    "                verbose=1,\n",
    "                validation_data=e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "10000/10000 [==============================] - 3s 254us/step - loss: 0.5339 - accuracy: 0.7781 - crossentropy: 0.5339 - val_loss: 1.2771 - val_accuracy: 0.1232 - val_crossentropy: 1.2771\n",
      "Epoch 2/5\n",
      "10000/10000 [==============================] - 2s 230us/step - loss: 0.4979 - accuracy: 0.7919 - crossentropy: 0.4979 - val_loss: 1.3912 - val_accuracy: 0.1009 - val_crossentropy: 1.3912\n",
      "Epoch 3/5\n",
      "10000/10000 [==============================] - 2s 231us/step - loss: 0.4774 - accuracy: 0.7925 - crossentropy: 0.4774 - val_loss: 1.0916 - val_accuracy: 0.3035 - val_crossentropy: 1.0916\n",
      "Epoch 4/5\n",
      "10000/10000 [==============================] - 2s 229us/step - loss: 0.4657 - accuracy: 0.7917 - crossentropy: 0.4657 - val_loss: 1.5232 - val_accuracy: 0.1373 - val_crossentropy: 1.5232\n",
      "Epoch 5/5\n",
      "10000/10000 [==============================] - 2s 238us/step - loss: 0.4640 - accuracy: 0.7950 - crossentropy: 0.4640 - val_loss: 1.3337 - val_accuracy: 0.1258 - val_crossentropy: 1.3337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f369574efd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model().fit(*e2,\n",
    "                batch_size=128,\n",
    "                epochs=5,\n",
    "                verbose=1,\n",
    "                validation_data=e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â 2) Claim: ERM on merged envs is fooled too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "e12 = (np.vstack([e1[0], e2[0]]), np.hstack([e1[1], e2[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 5s 225us/step - loss: 0.4547 - accuracy: 0.8372 - crossentropy: 0.4547 - val_loss: 1.8169 - val_accuracy: 0.0957 - val_crossentropy: 1.8169\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 4s 210us/step - loss: 0.4150 - accuracy: 0.8468 - crossentropy: 0.4150 - val_loss: 1.1267 - val_accuracy: 0.0962 - val_crossentropy: 1.1267\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.4030 - accuracy: 0.8469 - crossentropy: 0.4030 - val_loss: 1.4850 - val_accuracy: 0.1054 - val_crossentropy: 1.4850\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 4s 211us/step - loss: 0.3966 - accuracy: 0.8462 - crossentropy: 0.3966 - val_loss: 1.4074 - val_accuracy: 0.1528 - val_crossentropy: 1.4074\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.3906 - accuracy: 0.8469 - crossentropy: 0.3906 - val_loss: 1.4231 - val_accuracy: 0.0971 - val_crossentropy: 1.4231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f36442cd2d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model().fit(*e12,\n",
    "                batch_size=128,\n",
    "                epochs=5,\n",
    "                verbose=1,\n",
    "                validation_data=e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â 3) Claim: Robust ERM will be fooled too\n",
    "\n",
    "robust objective: $f = argmin_f \\{Â max_e R^e(f) - var(Y^e) \\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3263 0.24992603999999996 0.07637396000000002\n",
      "0.457 0.24998479000000007 0.20701520999999995\n"
     ]
    }
   ],
   "source": [
    "e1_loss = .3263\n",
    "e2_loss = .4570\n",
    "e1_var = e1[1].var()\n",
    "e2_var = e2[1].var()\n",
    "print(e1_loss, e1_var, e1_loss - e1_var)\n",
    "print(e2_loss, e2_var, e2_loss - e2_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â 3.1) jittering implem of robust objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f363c79c210>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jitter_color(x, scale=.25):\n",
    "    x_jit = x.copy()\n",
    "    for channel in (2,): #range(3):\n",
    "        mask = x_jit[:,:,channel] > 0\n",
    "        x_jit[:,:,channel] += mask * (np.random.normal(scale=scale, size=(28,28)))**2\n",
    "        if x_jit[:,:,channel].max() > 1.:\n",
    "            x_jit[:,:,channel] /= x_jit[:,:,channel].max()\n",
    "    return x_jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f363c777f10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_jit = jitter_color(x_train[5])\n",
    "plt.imshow(x_jit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc_jit 0.84785 train_acc 0.84755 ood_acc 0.101\n",
      "train_acc_jit 0.8483 train_acc 0.84485 ood_acc 0.1141\n",
      "train_acc_jit 0.84855 train_acc 0.84215 ood_acc 0.1239\n",
      "train_acc_jit 0.84075 train_acc 0.84785 ood_acc 0.0992\n",
      "train_acc_jit 0.8331 train_acc 0.8463 ood_acc 0.1142\n",
      "train_acc_jit 0.84835 train_acc 0.84845 ood_acc 0.0957\n",
      "train_acc_jit 0.8482 train_acc 0.84825 ood_acc 0.0968\n",
      "train_acc_jit 0.8484 train_acc 0.8484 ood_acc 0.0972\n",
      "train_acc_jit 0.84815 train_acc 0.8485 ood_acc 0.0957\n",
      "train_acc_jit 0.84835 train_acc 0.847 ood_acc 0.1031\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    e12_jit = np.array([jitter_color(xx, scale=.5) for xx in e12[0]])\n",
    "    m = get_model()\n",
    "    m.fit(e12_jit, e12[1],\n",
    "          batch_size=128,\n",
    "          epochs=3,\n",
    "          verbose=0)\n",
    "    y_pred_train_jit = (m.predict(e12_jit)[:,0] > .5).astype(int)\n",
    "    y_pred_train = (m.predict(e12[0])[:,0] > .5).astype(int)\n",
    "    y_pred_ood = (m.predict(e3[0])[:,0] > .5).astype(int)\n",
    "    print(\"train_acc_jit\", accuracy_score(e12[1], y_pred_train_jit), \n",
    "          \"train_acc\", accuracy_score(e12[1], y_pred_train), \n",
    "          \"ood_acc\", accuracy_score(e3[1], y_pred_ood))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Domain Adaptation: merged ERM with constraint on distrib_dist({phi(X^e)}_e=1..n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Adverserial Domain Adaptation\n",
    "http://openaccess.thecvf.com/content_cvpr_2017/papers/Tzeng_Adversarial_Discriminative_Domain_CVPR_2017_paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedEnvDataGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, adv_weight=.05, e1_weight=1.0, e2_weight=1.0, batch_size=128, shuffle=True):\n",
    "        \n",
    "        self.__load_initial_data()\n",
    "        self.__create_envs()\n",
    "        self.__create_validation_envs()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.halfbatch_size = int(np.floor(batch_size/2))\n",
    "        self.e1_weight = e1_weight\n",
    "        self.e2_weight = e2_weight\n",
    "        self.adv_weight = adv_weight\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.e1[1]))\n",
    "        print(len(self), 'batches/epoch')\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.e1[1]) / self.halfbatch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        \n",
    "        halfbatch_indices = self.indices[index*self.halfbatch_size:(index+1)*self.halfbatch_size]\n",
    "        \n",
    "        e1_x_batch = self.e1[0][halfbatch_indices,:,:,:]\n",
    "        e2_x_batch = self.e2[0][halfbatch_indices,:,:,:]\n",
    "        e1_y_batch = self.e1[1][halfbatch_indices]\n",
    "        e2_y_batch = self.e2[1][halfbatch_indices]\n",
    "        \n",
    "        mixed_x = np.vstack([\n",
    "            e1_x_batch,\n",
    "            e2_x_batch,\n",
    "        ])\n",
    "        \n",
    "        e1_y = np.hstack([e1_y_batch, np.zeros(self.halfbatch_size)])\n",
    "        e1_w = self.e1_weight * np.hstack([np.ones(self.halfbatch_size), np.zeros(self.halfbatch_size)])\n",
    "        \n",
    "        e2_y = np.hstack([np.zeros(self.halfbatch_size), e2_y_batch])\n",
    "        e2_w = self.e2_weight * np.hstack([np.zeros(self.halfbatch_size), np.ones(self.halfbatch_size)])\n",
    "        \n",
    "        adv_y = np.hstack([np.ones(self.halfbatch_size), np.zeros(self.halfbatch_size)])\n",
    "        adv_w = self.adv_weight * np.ones(len(adv_y))\n",
    "        \n",
    "        return [\n",
    "            mixed_x,\n",
    "            [e1_y, e2_y, adv_y],\n",
    "            [e1_w, e2_w, adv_w]\n",
    "        ]\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.e1[1]))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __load_initial_data(self):\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        # convert to RGB\n",
    "        x_train = np.stack((x_train,)*3, axis=-1)\n",
    "        x_test = np.stack((x_test,)*3, axis=-1)\n",
    "\n",
    "        # normalize\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train /= 255\n",
    "        x_test /= 255\n",
    "\n",
    "        # binary label\n",
    "        y_train = (y_train < 5).astype(int)\n",
    "        y_test = (y_test < 5).astype(int)\n",
    "        \n",
    "        self.original_data = {\n",
    "            'x_train':x_train,\n",
    "            'x_test':x_test,\n",
    "            'y_train':y_train,\n",
    "            'y_test':y_test\n",
    "        }\n",
    "        \n",
    "    def __create_envs(self):\n",
    "        self.e1 = self.__create_env(self.original_data['x_train'][:10000], \n",
    "                                    self.original_data['y_train'][:10000], .1)\n",
    "        self.e2 = self.__create_env(self.original_data['x_train'][10000:20000], \n",
    "                                    self.original_data['y_train'][10000:20000], .2)\n",
    "        self.e3 = self.__create_env(self.original_data['x_train'][20000:30000], \n",
    "                                    self.original_data['y_train'][20000:30000], .9)\n",
    "        \n",
    "    def __create_validation_envs(self):\n",
    "        self.e11 = self.__create_env(self.original_data['x_train'][30000:40000], \n",
    "                                     self.original_data['y_train'][30000:40000], .1)\n",
    "        self.e22 = self.__create_env(self.original_data['x_train'][40000:50000], \n",
    "                                     self.original_data['y_train'][40000:50000], .2)\n",
    "        self.e33 = self.__create_env(self.original_data['x_train'][50000:60000], \n",
    "                                     self.original_data['y_train'][50000:60000], .9)\n",
    "        half_len = int(len(self.e11[1])/2)\n",
    "        self.eaa = [\n",
    "            np.vstack([self.e11[0][:half_len], self.e22[0][:half_len]]),\n",
    "            np.hstack([np.ones(half_len), np.zeros(half_len)])\n",
    "        ]\n",
    "    \n",
    "    def __create_env(self, x, y, e, labelflip_proba=.25):\n",
    "        x = x.copy()\n",
    "        y = y.copy()\n",
    "\n",
    "        y = np.logical_xor(\n",
    "            y,\n",
    "            (np.random.random(size=len(y)) < labelflip_proba).astype(int)\n",
    "        ).astype(int)\n",
    "\n",
    "        color = np.logical_xor(\n",
    "            y,\n",
    "            (np.random.random(size=len(y)) < e).astype(int)\n",
    "        )\n",
    "\n",
    "        x[color, :, :, 2] = 0\n",
    "        x[color, :, :, 1] = 0\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ada_mixed_model():\n",
    "    \n",
    "    input_images = Input(shape=(28, 28, 3))\n",
    "    \n",
    "    cnn = Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu')(input_images)\n",
    "    cnn = Conv2D(64, (3, 3), activation='relu')(cnn)\n",
    "    cnn = MaxPooling2D(pool_size=(2, 2))(cnn)\n",
    "    cnn = Dropout(0.25)(cnn)\n",
    "    cnn = Flatten()(cnn)\n",
    "    \n",
    "    env1 = Dense(32, activation='relu')(cnn)\n",
    "    env1 = Dropout(0.5)(env1)\n",
    "    env1 = Dense(1, activation='sigmoid', name='env1')(env1)\n",
    "    \n",
    "    env2 = Dense(32, activation='relu')(cnn)\n",
    "    env2 = Dropout(0.5)(env2)\n",
    "    env2 = Dense(1, activation='sigmoid', name='env2')(env2)\n",
    "        \n",
    "    adv = Dense(32, activation='relu')(cnn)\n",
    "    adv = Dropout(0.5)(adv)\n",
    "    adv = Dense(1, activation='sigmoid', name='adv')(adv)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=[input_images],\n",
    "        outputs=[env1, env2, adv]\n",
    "    )\n",
    "    \n",
    "    def adv_loss(y_true, y_pred):\n",
    "        return - keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=[\n",
    "            keras.losses.binary_crossentropy,\n",
    "            keras.losses.binary_crossentropy,\n",
    "            adv_loss\n",
    "        ],\n",
    "        optimizer=keras.optimizers.Adadelta(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 batches/epoch\n",
      "  0 |e1->e11 acc: 0.901 | e2->e22 acc: 0.801 | e_a->eaa acc: 0.501 | e1->e3 acc: 0.101 e2->e3 acc: 0.141\n",
      "  1 |e1->e11 acc: 0.900 | e2->e22 acc: 0.798 | e_a->eaa acc: 0.501 | e1->e3 acc: 0.104 e2->e3 acc: 0.155\n",
      "  2 |e1->e11 acc: 0.900 | e2->e22 acc: 0.788 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.108 e2->e3 acc: 0.257\n",
      "  3 |e1->e11 acc: 0.897 | e2->e22 acc: 0.792 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.119 e2->e3 acc: 0.266\n",
      "  4 |e1->e11 acc: 0.894 | e2->e22 acc: 0.794 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.123 e2->e3 acc: 0.257\n",
      "  5 |e1->e11 acc: 0.890 | e2->e22 acc: 0.789 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.145 e2->e3 acc: 0.276\n",
      "  6 |e1->e11 acc: 0.888 | e2->e22 acc: 0.786 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.162 e2->e3 acc: 0.307\n",
      "  7 |e1->e11 acc: 0.502 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      "  8 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      "  9 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 10 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 11 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 12 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 13 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 14 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 15 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 16 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 17 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 18 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 19 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 20 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 21 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 22 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 23 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 24 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 25 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 26 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 27 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 28 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 29 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 30 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 31 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 32 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 33 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 34 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 35 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 36 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n",
      " 37 |e1->e11 acc: 0.501 | e2->e22 acc: 0.512 | e_a->eaa acc: 0.500 | e1->e3 acc: 0.508 e2->e3 acc: 0.508\n"
     ]
    }
   ],
   "source": [
    "m = get_ada_mixed_model()\n",
    "g = MixedEnvDataGenerator(adv_weight=5e-4, e1_weight=1, e2_weight=1, shuffle=True)\n",
    "logs = defaultdict(list)\n",
    "for _ in range(100):\n",
    "    m.fit_generator(\n",
    "        g,\n",
    "        epochs=5,\n",
    "        verbose=0,\n",
    "    )\n",
    "    print('%3d |'%_, end='')\n",
    "    (\n",
    "        loss_all, \n",
    "        e1_loss, e2_loss, adv_loss,\n",
    "        e1_acc, e2_acc, e3_acc\n",
    "    ) = m.evaluate(g.e11[0], [g.e11[1],g.e11[1],g.e11[1]], verbose=0)\n",
    "    logs['e11acc'] += [e1_acc]\n",
    "    logs['e11loss'] += [e1_loss]\n",
    "    print('e1->e11 acc: %.3f'%e1_acc, end=' | ')\n",
    "    (\n",
    "        loss_all, \n",
    "        e1_loss, e2_loss, adv_loss,\n",
    "        e1_acc, e2_acc, e3_acc\n",
    "    ) = m.evaluate(g.e22[0], [g.e22[1],g.e22[1],g.e22[1]], verbose=0)\n",
    "    logs['e22acc'] += [e2_acc]\n",
    "    logs['e22loss'] += [e2_loss]\n",
    "    print('e2->e22 acc: %.3f'%e2_acc, end=' | ')\n",
    "    (\n",
    "        loss_all, \n",
    "        e1_loss, e2_loss, adv_loss,\n",
    "        e1_acc, e2_acc, adv_acc\n",
    "    ) = m.evaluate(g.eaa[0], [g.eaa[1],g.eaa[1],g.eaa[1]], verbose=0)\n",
    "    logs['eaaacc'] += [adv_acc]\n",
    "    logs['eaaloss'] += [adv_loss]\n",
    "    print('e_a->eaa acc: %.3f'%adv_acc, end=' | ')\n",
    "    (\n",
    "        loss_all, \n",
    "        e1_loss, e2_loss, adv_loss,\n",
    "        e1_acc, e2_acc, e3_acc\n",
    "    ) = m.evaluate(g.e3[0], [g.e3[1], g.e3[1], g.e3[1]], verbose=0)\n",
    "    logs['e1_33acc'] += [e1_acc]\n",
    "    logs['e1_33loss'] += [e1_loss]\n",
    "    logs['e2_33acc'] += [e2_acc]\n",
    "    logs['e2_33loss'] += [e2_loss]\n",
    "    print('e1->e3 acc: %.3f'%e1_acc, 'e2->e3 acc: %.3f'%e2_acc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ('e11acc','e22acc','eaaacc','e1_33acc','e2_33acc'):\n",
    "    plt.plot(logs[k[:-3]+'loss'], label=k[:-3]+'loss')\n",
    "plt.legend(loc='center left')\n",
    "plt.grid()\n",
    "plt.yscale('symlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ('e11acc','e22acc','eaaacc','e1_33acc','e2_33acc'):\n",
    "    plt.plot(logs[k], label=k)\n",
    "plt.legend(loc='center left')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â TODO IRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "        \n",
    "    input_images = Input(shape=(28, 28, 3))\n",
    "    \n",
    "    cnn = Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu')(input_images)\n",
    "    cnn = Conv2D(64, (3, 3), activation='relu')(cnn)\n",
    "    cnn = MaxPooling2D(pool_size=(2, 2))(cnn)\n",
    "    cnn = Dropout(0.25)(cnn)\n",
    "    cnn = Flatten()(cnn)\n",
    "    \n",
    "    spe = Dense(32, activation='relu')(cnn)\n",
    "    spe = Dropout(0.5)(spe)\n",
    "    \n",
    "    # IRM part\n",
    "    \n",
    "    w1 = np.zeros(32)\n",
    "    w1[0] = 1    \n",
    "    irm = Dense(1, activation='sigmoid', name='env', \n",
    "                bias_initializer=keras.initializers.Zeros(),\n",
    "                kernel_initializer=keras.initializers.Constant(value=w1),\n",
    "                use_bias=False,\n",
    "                trainable=False)(spe)\n",
    "    irm_model = Model(\n",
    "        inputs=[input_images],\n",
    "        outputs=[irm]\n",
    "    )\n",
    "    \n",
    "    class IRMLoss(object):\n",
    "        def __init__(self, lambda_=1):\n",
    "            self.lambda_=lambda_\n",
    "            self.dummy_grad_norm = 0\n",
    "            self.loss = 1\n",
    "            self.accuracy = 0\n",
    "            self.penalty = 1\n",
    "            \n",
    "        def update(self, model, x, y):\n",
    "            \n",
    "            self.loss, self.accuracy = model.evaluate(x,y,verbose=0)\n",
    "\n",
    "            output_tensors = model.optimizer.get_gradients(model.total_loss, model.layers[-1].weights[0])\n",
    "            input_tensors = model.inputs + model.sample_weights + model.targets + [K.learning_phase()]\n",
    "            get_gradients = K.function(inputs=input_tensors, outputs=output_tensors)\n",
    "            inputs = [x, np.ones(len(y)), y, 0]\n",
    "            grads = get_gradients(inputs)\n",
    "            self.dummy_grad_norm = np.sqrt(np.sum([_**2 for _ in grads[0]]))\n",
    "            \n",
    "            self.penalty = np.sum([self.loss * _**2 for _ in grads[0]])\n",
    "            \n",
    "        def __call__(self, y_true, y_pred, sample_weight=None):\n",
    "            loss = keras.losses.binary_crossentropy(y_true, y_pred) + self.lambda_ * self.penalty\n",
    "            #if loss > 1:\n",
    "            #    return loss / self.lambda_\n",
    "            return loss\n",
    "    \n",
    "    irm_loss = IRMLoss()\n",
    "    \n",
    "    irm_model.compile(\n",
    "        loss=keras.losses.binary_crossentropy,\n",
    "        optimizer=keras.optimizers.Adadelta(),\n",
    "        metrics=['accuracy']\n",
    "    )    \n",
    "    \n",
    "    if True:\n",
    "        baseline = Dense(1, activation='sigmoid', name='base', \n",
    "                         use_bias=False,\n",
    "                         trainable=True)(spe)\n",
    "        baseline_model = Model(\n",
    "            inputs=input_images,\n",
    "            outputs=baseline\n",
    "        )\n",
    "        baseline_model.compile(\n",
    "            loss=irm_loss,\n",
    "            optimizer=keras.optimizers.Adadelta(),\n",
    "            metrics=['accuracy']\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irm_loss.lambda_*irm_loss.penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step size: 1000\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5\n",
      "--------------------------------------------------------------------------------\n",
      "lam:      0 | pen: 0.185 loss: 1.309 acc: 0.899 | pen: 0.116 loss: 1.482 acc: 0.799 | e3loss: 2.245 e3acc: 0.108\n",
      "lam:      0 | pen: 0.060 loss: 1.350 acc: 0.897 | pen: 0.130 loss: 1.459 acc: 0.799 | e3loss: 2.261 e3acc: 0.113\n",
      "lam:      0 | pen: 0.117 loss: 1.342 acc: 0.896 | pen: 0.187 loss: 1.471 acc: 0.799 | e3loss: 2.205 e3acc: 0.100\n",
      "lam:      0 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-368741e2683e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mirm_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mirm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_pr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"| pen:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%.3f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mirm_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-192-6f0c8d6ea272>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, model, x, y)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mget_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.7/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             raise ValueError('An operation has `None` for gradient. '\n",
      "\u001b[0;32m~/miniconda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   3023\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_tf_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3024\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3025\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients_v2\u001b[0;34m(ys, xs, grad_ys, name, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         unconnected_gradients)\n\u001b[0m\u001b[1;32m    275\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0mstop_gradient_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     reachable_to_ops, pending_count, loop_state = _PendingCount(\n\u001b[0;32m--> 551\u001b[0;31m         to_ops, from_ops, colocate_gradients_with_ops, func_graphs, xs_set)\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;31m# Iterate over the collected ops.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_PendingCount\u001b[0;34m(to_ops, from_ops, colocate_gradients_with_ops, func_graphs, xs_set)\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;31m# Mark reachable ops from from_ops.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mreached_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0m_MarkReachedOps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreached_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m   \u001b[0;31m# X in reached_ops iff X is reachable from from_ops by a path of zero or more\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;31m# backpropagatable tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MarkReachedOps\u001b[0;34m(from_ops, reached_ops, func_graphs)\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_IsBackpropagatable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m           \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Consumers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_Consumers\u001b[0;34m(t, func_graphs)\u001b[0m\n\u001b[1;32m    471\u001b[0m   \u001b[0mconsumers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunc_graphs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_Captures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_t\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mconsumers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Consumers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step_size = 1000#int(len(e1[1])/10)\n",
    "print(\"Step size:\", step_size)\n",
    "\n",
    "n_pr = 1\n",
    "\n",
    "for epoch in range(5,15):\n",
    "    \n",
    "    print('-'*80)\n",
    "    print('Epoch', epoch)\n",
    "    print('-'*80)\n",
    "    \n",
    "    for batch in range(int(len(e1[1])/step_size)-1):\n",
    "        irm_loss.lambda_ = 0#epoch*10000\n",
    "        if not batch % n_pr: print(\"lam: %6d\" % irm_loss.lambda_, end=' ')\n",
    "        for env in (e1, e2):\n",
    "            x = env[0][batch*step_size:(batch+1)*step_size,:,:,:]\n",
    "            y = env[1][batch*step_size:(batch+1)*step_size]\n",
    "\n",
    "            irm_loss.update(irm_model, x, y)\n",
    "            if not batch % n_pr:\n",
    "                print(\"| pen:\", '%.3f'%irm_loss.penalty, end=' ')\n",
    "                loss, acc = baseline_model.evaluate(env[0], env[1], verbose=0)\n",
    "                print(\"loss:\", '%.3f'%loss, \"acc:\",'%.3f'%acc, end=' ')\n",
    "\n",
    "            baseline_model.fit(x=x, y=y, batch_size=step_size, epochs=1, shuffle=True, verbose=0)\n",
    "\n",
    "        if not batch % n_pr:\n",
    "            loss, acc = baseline_model.evaluate(e3[0],e3[1],verbose=0)\n",
    "            print(\"| e3loss:\", '%.3f'%loss, \"e3acc:\", '%.3f'%acc)\n",
    "\n",
    "for env in (e1, e2, e3):\n",
    "    loss, acc = baseline_model.evaluate(env[0], env[1], verbose=0)\n",
    "    print(\"| e3loss:\", '%.3f'%loss, \"e3acc:\", '%.3f'%acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
