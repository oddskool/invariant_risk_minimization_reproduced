{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, Multiply\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv3D, MaxPool3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColoredMNISTEnvironments():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.__load_initial_data()\n",
    "        self.__create_envs()\n",
    "        self.__create_validation_envs()\n",
    "\n",
    "    def __load_initial_data(self):\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        # convert to RGB\n",
    "        x_train = np.stack((x_train,)*3, axis=-1)\n",
    "        x_test = np.stack((x_test,)*3, axis=-1)\n",
    "\n",
    "        # normalize\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train /= 255\n",
    "        x_test /= 255\n",
    "\n",
    "        # binary label\n",
    "        y_train = (y_train < 5).astype(int)\n",
    "        y_test = (y_test < 5).astype(int)\n",
    "        \n",
    "        self.original_data = {\n",
    "            'x_train':x_train,\n",
    "            'x_test':x_test,\n",
    "            'y_train':y_train,\n",
    "            'y_test':y_test\n",
    "        }\n",
    "        \n",
    "    def __create_envs(self):\n",
    "        k=10**4\n",
    "        self.e1 = self.__create_env(self.original_data['x_train'][:k], \n",
    "                                    self.original_data['y_train'][:k], .1)\n",
    "        self.e2 = self.__create_env(self.original_data['x_train'][k:2*k], \n",
    "                                    self.original_data['y_train'][k:2*k], .2)\n",
    "        self.e3 = self.__create_env(self.original_data['x_train'][2*k:3*k], \n",
    "                                    self.original_data['y_train'][2*k:3*k], .9)\n",
    "        \n",
    "    def __create_validation_envs(self):\n",
    "        k=10**4\n",
    "        i=3*k\n",
    "        self.e11 = self.__create_env(self.original_data['x_train'][i:i+k], \n",
    "                                     self.original_data['y_train'][i:i+k], .1)\n",
    "        self.e22 = self.__create_env(self.original_data['x_train'][i+k:i+2*k], \n",
    "                                     self.original_data['y_train'][i+k:i+2*k], .2)\n",
    "        self.e33 = self.__create_env(self.original_data['x_train'][i+2*k:i+3*k], \n",
    "                                     self.original_data['y_train'][i+2*k:i+3*k], .9)\n",
    "        \n",
    "    def __create_env(self, x, y, e, labelflip_proba=.25):\n",
    "        x = x.copy()\n",
    "        y = y.copy()\n",
    "\n",
    "        y = np.logical_xor(\n",
    "            y,\n",
    "            (np.random.random(size=len(y)) < labelflip_proba).astype(int)\n",
    "        ).astype(int)\n",
    "\n",
    "        color = np.logical_xor(\n",
    "            y,\n",
    "            (np.random.random(size=len(y)) < e).astype(int)\n",
    "        )\n",
    "\n",
    "        x[color, :, :, 2] = 0\n",
    "        x[color, :, :, 1] = 0\n",
    "        return tf.data.Dataset.from_tensor_slices((x, y))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(compile=False):\n",
    "    \n",
    "    input_images = Input(shape=(28, 28, 3))\n",
    "    \n",
    "    cnn = Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu')(input_images)\n",
    "    cnn = Conv2D(64, (3, 3), activation='relu')(cnn)\n",
    "    cnn = MaxPooling2D(pool_size=(2, 2))(cnn)\n",
    "    cnn = Dropout(0.25)(cnn)\n",
    "    cnn = Flatten()(cnn)\n",
    "    \n",
    "    env1 = Dense(32, activation='relu')(cnn)\n",
    "    env1 = Dropout(0.5)(env1)\n",
    "    env1 = Dense(1, name='env1')(env1)\n",
    "        \n",
    "    model = Model(\n",
    "        inputs=[input_images],\n",
    "        outputs=[env1]\n",
    "    )\n",
    "    \n",
    "    if compile:\n",
    "        model.compile(\n",
    "            loss=[\n",
    "                tf.keras.losses.binary_crossentropy,\n",
    "            ],\n",
    "            optimizer=tf.keras.optimizers.Adadelta(),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_envs = ColoredMNISTEnvironments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, valid_dataset, epochs, lambdas, \n",
    "          dummy=tf.convert_to_tensor([1.]),\n",
    "          loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "          accuracy_object = tf.keras.metrics.Accuracy(),\n",
    "          optimizer = tf.keras.optimizers.Adam()):\n",
    "  for epoch in range(epochs):\n",
    "    lambda_ = lambdas[epoch]\n",
    "    for (batch, (images, labels)) in enumerate(dataset):\n",
    "    \n",
    "      # compute penalty\n",
    "      with tf.GradientTape() as tape:\n",
    "        tape.watch(dummy)\n",
    "        logits = model(images, training=False)\n",
    "        loss_value = loss_object(labels, logits * dummy)\n",
    "      accuracy_object.update_state(labels, \n",
    "                                   tf.math.greater(\n",
    "                                       tf.keras.activations.sigmoid(logits),\n",
    "                                       .5)\n",
    "                                   )\n",
    "      grads = tape.gradient(loss_value, dummy)\n",
    "      penalty = tf.math.reduce_mean(loss_value * tf.math.square(grads)).numpy()\n",
    "    \n",
    "      # train\n",
    "      with tf.GradientTape() as tape:\n",
    "        logits = model(images, training=True)\n",
    "        loss_value = loss_object(labels, logits)\n",
    "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "      grads += penalty * lambda_\n",
    "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "      if not batch % 30:\n",
    "        tr_acc = accuracy_object.result().numpy()\n",
    "        accuracy_object.reset_states()\n",
    "        # validation\n",
    "        for (v_batch, (v_images, v_labels)) in enumerate(valid_dataset):\n",
    "          logits = model(v_images, training=False)\n",
    "          accuracy_object.update_state(v_labels, \n",
    "                                       tf.math.greater(\n",
    "                                         tf.keras.activations.sigmoid(logits),\n",
    "                                         .5)\n",
    "                                       )\n",
    "        v_acc = accuracy_object.result().numpy()\n",
    "        accuracy_object.reset_states()\n",
    "        print ('Epoch %3d TrainLoss %.5f Penalty %.5f TrainAcc %.3f TestAcc %.3f' % (\n",
    "            epoch, loss_value.numpy().mean(), penalty, tr_acc, v_acc \n",
    "        ))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 TrainLoss 0.69673 Penalty 0.00000 TrainAcc 0.539 TestAcc 0.795\n",
      "Epoch   0 TrainLoss 0.39744 Penalty 0.00158 TrainAcc 0.900 TestAcc 0.903\n",
      "Epoch   0 TrainLoss 0.34157 Penalty 0.00084 TrainAcc 0.898 TestAcc 0.903\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    get_model(), \n",
    "    mnist_envs.e1.shuffle(256).batch(128), \n",
    "    mnist_envs.e11.shuffle(256).batch(128), \n",
    "    epochs = 1, \n",
    "    lambdas = [0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 TrainLoss 0.70284 Penalty 0.00004 TrainAcc 0.881 TestAcc 0.793\n",
      "Epoch   0 TrainLoss 0.37105 Penalty 0.00120 TrainAcc 0.901 TestAcc 0.796\n",
      "Epoch   0 TrainLoss 0.52029 Penalty 0.03031 TrainAcc 0.897 TestAcc 0.796\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    get_model(), \n",
    "    mnist_envs.e1.shuffle(256).batch(128), \n",
    "    mnist_envs.e2.shuffle(256).batch(128), \n",
    "    epochs = 1, \n",
    "    lambdas = [0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 TrainLoss 0.69566 Penalty 0.00001 TrainAcc 0.880 TestAcc 0.493\n",
      "Epoch   0 TrainLoss 0.33700 Penalty 0.00000 TrainAcc 0.890 TestAcc 0.810\n",
      "Epoch   0 TrainLoss 0.27881 Penalty 0.00393 TrainAcc 0.902 TestAcc 0.810\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    get_model(), \n",
    "    mnist_envs.e11.shuffle(256).batch(128), \n",
    "    mnist_envs.e22.shuffle(256).batch(128), \n",
    "    epochs = 1, \n",
    "    lambdas = [0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 TrainLoss 0.68854 Penalty 0.00000 TrainAcc 0.878 TestAcc 0.491\n",
      "Epoch   0 TrainLoss 0.55199 Penalty 0.00109 TrainAcc 0.782 TestAcc 0.899\n",
      "Epoch   0 TrainLoss 0.53440 Penalty 0.00001 TrainAcc 0.795 TestAcc 0.899\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    get_model(), \n",
    "    mnist_envs.e2.shuffle(256).batch(128), \n",
    "    mnist_envs.e1.shuffle(256).batch(128), \n",
    "    epochs = 1, \n",
    "    lambdas = [0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 TrainLoss 0.69673 Penalty 0.00001 TrainAcc 0.874 TestAcc 0.329\n",
      "Epoch   0 TrainLoss 0.32922 Penalty 0.00074 TrainAcc 0.886 TestAcc 0.099\n",
      "Epoch   0 TrainLoss 0.33516 Penalty 0.00146 TrainAcc 0.899 TestAcc 0.099\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    get_model(), \n",
    "    mnist_envs.e1.shuffle(256).batch(128), \n",
    "    mnist_envs.e3.shuffle(256).batch(128), \n",
    "    epochs = 1, \n",
    "    lambdas = [0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 TrainLoss 0.70098 Penalty 0.00001 TrainAcc 0.878 TestAcc 0.379\n",
      "Epoch   0 TrainLoss 0.38374 Penalty 0.00027 TrainAcc 0.887 TestAcc 0.099\n",
      "Epoch   0 TrainLoss 0.43384 Penalty 0.00162 TrainAcc 0.898 TestAcc 0.099\n",
      "Epoch   0 TrainLoss 0.55759 Penalty 0.00041 TrainAcc 0.858 TestAcc 0.099\n",
      "Epoch   0 TrainLoss 0.51440 Penalty 0.00195 TrainAcc 0.801 TestAcc 0.099\n",
      "Epoch   0 TrainLoss 0.51244 Penalty 0.00595 TrainAcc 0.792 TestAcc 0.099\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    get_model(), \n",
    "    mnist_envs.e1.concatenate(mnist_envs.e2).shuffle(256).batch(128),\n",
    "    mnist_envs.e3.shuffle(256).batch(128), \n",
    "    epochs = 1, \n",
    "    lambdas = [0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 TrainLoss 0.69155 Penalty 0.00002 TrainAcc 0.735 TestAcc 0.491\n",
      "Epoch   0 TrainLoss 0.41020 Penalty 0.00093 TrainAcc 0.887 TestAcc 0.099\n",
      "Epoch   0 TrainLoss 0.32322 Penalty 0.00237 TrainAcc 0.898 TestAcc 0.099\n",
      "Epoch   0 TrainLoss 0.49490 Penalty 0.00702 TrainAcc 0.859 TestAcc 0.101\n",
      "Epoch   0 TrainLoss 0.44098 Penalty 0.00200 TrainAcc 0.798 TestAcc 0.104\n",
      "Epoch   0 TrainLoss 0.49879 Penalty 0.00003 TrainAcc 0.794 TestAcc 0.105\n",
      "Epoch   1 TrainLoss 0.42940 Penalty 0.00689 TrainAcc 0.784 TestAcc 0.108\n",
      "Epoch   1 TrainLoss 0.35474 Penalty 0.00009 TrainAcc 0.899 TestAcc 0.099\n",
      "Epoch   1 TrainLoss 0.29648 Penalty 0.00002 TrainAcc 0.900 TestAcc 0.099\n",
      "Epoch   1 TrainLoss 0.49480 Penalty 0.00059 TrainAcc 0.855 TestAcc 0.104\n",
      "Epoch   1 TrainLoss 0.49123 Penalty 0.00192 TrainAcc 0.799 TestAcc 0.105\n",
      "Epoch   1 TrainLoss 0.43876 Penalty 0.00322 TrainAcc 0.795 TestAcc 0.116\n",
      "Epoch   2 TrainLoss 0.39052 Penalty 0.00156 TrainAcc 0.789 TestAcc 0.119\n",
      "Epoch   2 TrainLoss 0.33577 Penalty 0.00003 TrainAcc 0.898 TestAcc 0.099\n",
      "Epoch   2 TrainLoss 0.39945 Penalty 0.00382 TrainAcc 0.899 TestAcc 0.099\n",
      "Epoch   2 TrainLoss 0.54776 Penalty 0.00040 TrainAcc 0.856 TestAcc 0.111\n",
      "Epoch   2 TrainLoss 0.50944 Penalty 0.00237 TrainAcc 0.799 TestAcc 0.109\n",
      "Epoch   2 TrainLoss 0.49128 Penalty 0.00002 TrainAcc 0.791 TestAcc 0.126\n",
      "Epoch   3 TrainLoss 0.36193 Penalty 0.00497 TrainAcc 0.805 TestAcc 0.122\n",
      "Epoch   3 TrainLoss 0.31987 Penalty 0.00000 TrainAcc 0.896 TestAcc 0.101\n",
      "Epoch   3 TrainLoss 0.32569 Penalty 0.00044 TrainAcc 0.898 TestAcc 0.099\n",
      "Epoch   3 TrainLoss 0.48615 Penalty 0.00155 TrainAcc 0.859 TestAcc 0.107\n",
      "Epoch   3 TrainLoss 0.52737 Penalty 0.00074 TrainAcc 0.796 TestAcc 0.112\n",
      "Epoch   3 TrainLoss 0.53941 Penalty 0.00001 TrainAcc 0.795 TestAcc 0.120\n",
      "Epoch   4 TrainLoss 0.33457 Penalty 0.00303 TrainAcc 0.796 TestAcc 0.117\n",
      "Epoch   4 TrainLoss 0.28509 Penalty 0.00022 TrainAcc 0.899 TestAcc 0.100\n",
      "Epoch   4 TrainLoss 0.33165 Penalty 0.00003 TrainAcc 0.896 TestAcc 0.102\n",
      "Epoch   4 TrainLoss 0.46120 Penalty 0.00055 TrainAcc 0.860 TestAcc 0.120\n",
      "Epoch   4 TrainLoss 0.42350 Penalty 0.00163 TrainAcc 0.799 TestAcc 0.116\n",
      "Epoch   4 TrainLoss 0.47834 Penalty 0.00101 TrainAcc 0.793 TestAcc 0.129\n",
      "Epoch   5 TrainLoss 0.42732 Penalty 0.00195 TrainAcc 0.785 TestAcc 0.123\n",
      "Epoch   5 TrainLoss 0.30540 Penalty 0.00000 TrainAcc 0.899 TestAcc 0.101\n",
      "Epoch   5 TrainLoss 0.32343 Penalty 0.00002 TrainAcc 0.895 TestAcc 0.100\n",
      "Epoch   5 TrainLoss 0.43398 Penalty 0.00050 TrainAcc 0.859 TestAcc 0.110\n",
      "Epoch   5 TrainLoss 0.41653 Penalty 0.00024 TrainAcc 0.800 TestAcc 0.113\n",
      "Epoch   5 TrainLoss 0.51083 Penalty 0.00003 TrainAcc 0.794 TestAcc 0.120\n",
      "Epoch   6 TrainLoss 0.30918 Penalty 0.00855 TrainAcc 0.805 TestAcc 0.121\n",
      "Epoch   6 TrainLoss 0.45155 Penalty 0.01355 TrainAcc 0.895 TestAcc 0.106\n",
      "Epoch   6 TrainLoss 0.33273 Penalty 0.00050 TrainAcc 0.899 TestAcc 0.105\n",
      "Epoch   6 TrainLoss 0.51205 Penalty 0.00001 TrainAcc 0.856 TestAcc 0.109\n",
      "Epoch   6 TrainLoss 0.60008 Penalty 0.00537 TrainAcc 0.799 TestAcc 0.116\n",
      "Epoch   6 TrainLoss 0.48706 Penalty 0.00256 TrainAcc 0.795 TestAcc 0.123\n",
      "Epoch   7 TrainLoss 0.40265 Penalty 0.00367 TrainAcc 0.793 TestAcc 0.121\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-fbac02ba6076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmnist_envs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-16-7a09be73fcb8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, valid_dataset, epochs, lambda_, dummy, loss_object, accuracy_object, optimizer)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m           \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m           accuracy_object.update_state(v_labels, \n\u001b[1;32m     38\u001b[0m                                        tf.math.greater(\n",
      "\u001b[0;32m~/miniconda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    715\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    716\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;31m# explicitly take priority.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[0mmask_arg_passed_by_framework\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0minput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collect_input_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m     if (self._expects_mask_arg and input_masks is not None and\n\u001b[1;32m    680\u001b[0m         not self._call_arg_was_passed('mask', args, kwargs)):\n",
      "\u001b[0;32m~/miniconda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_collect_input_masks\u001b[0;34m(self, inputs, args, kwargs)\u001b[0m\n\u001b[1;32m   1958\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_collect_input_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m     \u001b[0;34m\"\"\"Checks if `mask` argument was passed, else gathers mask from inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_arg_was_passed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1961\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_call_arg_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_call_arg_was_passed\u001b[0;34m(self, arg_name, args, kwargs, inputs_in_args)\u001b[0m\n\u001b[1;32m   1977\u001b[0m       \u001b[0;31m# Ignore `inputs` arg.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m       \u001b[0mcall_fn_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1979\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_fn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1980\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(\n",
    "    get_model(), \n",
    "    mnist_envs.e1.concatenate(mnist_envs.e2).shuffle(256).batch(128),\n",
    "    mnist_envs.e3.batch(128), \n",
    "    epochs = 10, \n",
    "    lambdas = [0,0,1,1,5,5,10,10,100,1000]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
